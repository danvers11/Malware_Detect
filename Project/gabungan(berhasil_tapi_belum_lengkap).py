# -*- coding: utf-8 -*-
"""Gabungan(berhasil - tapi belum lengkap).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wssBCvCM1jlKMbO_6NwNP00uluX5uVg-
"""

pip install scikit-plot

import os
import keras
import matplotlib.pyplot as plt
import numpy as np
import scikitplot as skpl
import tensorflow as tf
import scipy as sp
from tensorflow.keras.layers import InputLayer
from tensorflow.keras.models import Sequential, Model
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout, Flatten , BatchNormalization
from keras.layers import Conv2D, MaxPooling2D , AveragePooling2D, GlobalAveragePooling2D
from tensorflow.keras import models, layers
from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping
from tensorflow.keras.optimizers import Adam

"""Connect to dataset from Drive"""

from google.colab import drive
import os

drive.mount('/content/drive/')

base_dir = '/content/drive/My Drive/Dataset/dataset_9010/malimg_dataset'
train = "/content/drive/My Drive/Dataset/dataset_9010/malimg_dataset/train"
val = "/content/drive/My Drive/Dataset/dataset_9010/malimg_dataset/validation"

batch_size=32
IMAGE_SIZE = [150, 150]

dataset = tf.keras.preprocessing.image_dataset_from_directory(
    train,
    seed = 123,
    shuffle = True,
    image_size = (150,150),
    batch_size = batch_size
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    val,
    seed = 123,
    shuffle = True,
    image_size = (150,150),
    batch_size = batch_size
)

class_names = dataset.class_names

plt.figure(figsize = (10, 10))
perc = []
class_name = []
for image_batch, labels_batch in dataset.take(1):
    for i in range(len(image_batch)):
        ax = plt.subplot(4, 8, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        class_name.append(class_names[labels_batch[i]])
        perc.append((labels_batch[i].numpy().astype("uint8")/image_batch[i].numpy().astype("uint8").shape[0])*100)
        plt.axis("off")

plt.xticks(rotation='vertical')
# print(class_name)
plt.bar(class_name,perc)

"""Splitting Data to train and test"""

def get_dataset_partitions_tf(ds, train_split = 0.9, test_split = 0.1, shuffle = True, shuffle_size = 10000):
    assert (train_split + test_split) == 1
    
    ds_size = len(ds)
    
    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)
    
    train_size = int(train_split * ds_size)
    test_size = int(test_split * ds_size)
    
    train_ds = ds.take(train_size)    
    test_ds = ds.skip(train_size).take(test_size)
    
    
    return train_ds, test_ds

train_ds, test_ds = get_dataset_partitions_tf(dataset)

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)

"""We build our model using Keras."""

num_classes = 25

def malware_model(width , height):
    Malware_model = Sequential()
    Malware_model.add(Conv2D(30, kernel_size = (3, 3),
                     activation = 'relu',
                     input_shape = (width, height, 3)))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
    Malware_model.add(Conv2D(15, (3, 3), activation = 'relu'))
    Malware_model.add(MaxPooling2D(pool_size = (2, 2)))
    Malware_model.add(Dropout(0.25))
    Malware_model.add(Flatten())
    Malware_model.add(Dense(128, activation = 'relu'))
    Malware_model.add(Dropout(0.5))
    Malware_model.add(Dense(50, activation = 'relu'))
    Malware_model.add(Dense(num_classes, activation = 'softmax'))
    Malware_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), optimizer = 'adam', metrics = ['accuracy'])
    return Malware_model

"""Without Scaling Model"""

model = malware_model(150 , 150)

model_fit = model.fit(train_ds, epochs = 30 ,batch_size = batch_size, validation_data = val_ds, verbose =1)

model.evaluate(test_ds)

# plot the loss
plt.title("Learning Curve")
plt.xlabel("Training Set Size")
plt.plot(model_fit.history['loss'], label = 'train loss')
plt.ylabel("RMSE")
plt.title('train_loss')
plt.plot(model_fit.history['val_loss'], label = 'val loss')
plt.title('val_loss')
plt.legend()

plt.show()
plt.savefig('LossVal_loss.jpg',format = 'jpg')

plt.close()

# plot the accuracy
plt.title("Learning Curve")
plt.xlabel("Training Set Size")
plt.plot(model_fit.history['accuracy'], label = 'train acc')
plt.ylabel("RMSE")
plt.title('train_acc')
plt.plot(model_fit.history['val_accuracy'], label = 'val acc')
plt.title('val_acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc.jpg',format = "jpg")

plt.close()

"""Saving the Model"""

model.save("./Malimg_model.h5")

"""Model with Scaling"""

resize_and_rescale = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(150, 150),
  layers.experimental.preprocessing.Rescaling(1./255)
])

def malware_model(width , height):
    Malware_model = Sequential()
    
    Malware_model.add(resize_and_rescale)
    Malware_model.add(Conv2D(30, kernel_size=(3, 3),
                     activation = 'relu',
                     input_shape = (batch_size, width, height, 3)))

    Malware_model.add(MaxPooling2D(pool_size = (2, 2)))
    Malware_model.add(Conv2D(15, (3, 3), activation = 'relu'))
    Malware_model.add(MaxPooling2D(pool_size = (2, 2)))
    Malware_model.add(Dropout(0.25))
    Malware_model.add(Flatten())
    Malware_model.add(Dense(128, activation = 'relu'))
    Malware_model.add(Dropout(0.5))
    Malware_model.add(Dense(num_classes, activation = 'relu'))
    
    Malware_model.add(Dense(25, activation = 'softmax'))
    Malware_model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False), optimizer = 'adam', metrics = ['accuracy'])
    return Malware_model

EPOCH = 100

lr_reduction = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 4, verbose = 1,  factor = 0.4, min_lr = 0.0001)

early_stop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0.00001, patience = 8, mode = 'auto', restore_best_weights = True)

model = malware_model(150 , 150)
model_fit = model.fit(train_ds, epochs = EPOCH, batch_size = batch_size, validation_data = val_ds, verbose = 1, callbacks = [early_stop,lr_reduction])

model.evaluate(test_ds)

model.save("./Best_Model.h5")

# plot the loss
plt.title("Learning Curve")
plt.xlabel("Training Set Size")
plt.plot(model_fit.history['loss'], label = 'train loss')
plt.ylabel("RMSE")
plt.plot(model_fit.history['val_loss'], label = 'val loss')
plt.legend()

plt.show()

plt.close()
# plot the accuracy
plt.title("Learning Curve")
plt.xlabel("Training Set Size")
plt.plot(model_fit.history['accuracy'], label = 'train acc')
plt.ylabel("RMSE")
plt.plot(model_fit.history['val_accuracy'], label = 'val acc')
plt.legend()
plt.show()


plt.close()

"""Without Scaling Is The Best Model"""

for images_batch, labels_batch in test_ds.take(1):
    
    first_image = images_batch[0].numpy().astype('uint8')
    first_label = labels_batch[0].numpy()
    
    print("first image to predict")
    plt.imshow(first_image)
    print("actual label:", class_names[first_label])
    
    batch_prediction = model.predict(images_batch)
    print("predicted label:", class_names[np.argmax(batch_prediction[0])])

def predict(model, img):
    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy())
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)

    predicted_class = class_names[np.argmax(predictions[0])]
    confidence = round(100 * (np.max(predictions[0])), 2)
    return predicted_class, confidence

plt.figure(figsize = (15, 15))
for images, labels in test_ds.take(3):
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        
        predicted_class, confidence = predict(model, images[i].numpy())
        actual_class = class_names[labels[i]] 
        
        plt.title(f"Actual: {actual_class},\n Predicted: {predicted_class}.\n Confidence: {confidence}%")
        
        plt.axis("off")

model.summary()

from keras.models import load_model
model = load_model("./Best_Model.h5")

"""Predicting a random image"""

from tensorflow.keras.utils import load_img, img_to_array
img_path = "../content/drive/MyDrive/Dataset/dataset_9010/malimg_dataset/validation/Adialer.C/008a92e720e896caea4a251e6a4c9934.png"

img = load_img(img_path, target_size = (150, 150))
img_tensor = img_to_array(img)                    # (height, width, channels)
img_tensor = np.expand_dims(img_tensor, axis = 0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)
                                      # imshow expects values in the range [0, 1]

pred=model.predict(img_tensor)
print(class_names[np.argmax(pred)])

fig, ax = plt.subplots(1,2, figsize=[12,6])
ax[0].plot(dataset.dataset["loss"])
ax[0].plot(dataset.dataset["val_loss"])
ax[0].set_title(" Loss")
ax[0].legend(("Training", "validation"), loc="upper right")
ax[0].set_xlabel("Epochs")
ax[1].plot(dataset.dataset["accuracy"])
ax[1].plot(dataset.dataset["val_accuracy"])
ax[1].legend(("Training", "validation"), loc="lower right")
ax[1].set_title("Accuracy")
ax[1].set_xlabel("Epochs")